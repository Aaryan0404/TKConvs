#include <iostream>
#include <chrono>
#include <string>
#include <stdlib.h>
#include <float.h>
#include <fstream>

#define N 64

#define H 256
#define W 256
#define P 256
#define Q 256

#define C 128

#define K 128

#define R 3
#define S 3

#define CudaCheckError()    __cudaCheckError( __FILE__, __LINE__ )
inline void __cudaCheckError( const char *file, const int line ) {
    cudaError err = cudaGetLastError();
    if ( cudaSuccess != err )
    {
        fprintf( stderr, "cudaCheckError() failed at %s:%i : %s\n",
                 file, line, cudaGetErrorString( err ) );
        exit( -1 );
    }
    // More careful checking. However, this will affect performance.
    // Comment away if needed.
    err = cudaDeviceSynchronize();
    if( cudaSuccess != err )
    {
        fprintf( stderr, "cudaCheckError() with sync failed at %s:%i : %s\n",
                 file, line, cudaGetErrorString( err ) );
        exit( -1 );
    }
}

int main(int argc, char **argv) {
    constexpr long long TOTAL_ELEMENTS_INPUT         = static_cast<long long>(N) * H * W * C * R * S;
    constexpr long long TOTAL_UNIQUE_ELEMENTS_INPUT  = static_cast<long long>(H) * W * C * R * S;
    constexpr long long TOTAL_ELEMENTS_WEIGHT        = static_cast<long long>(K) * C * R * S;
    constexpr long long TOTAL_ELEMENTS_OUTPUT        = static_cast<long long>(N) * P * Q * K;
    constexpr long long TOTAL_UNIQUE_ELEMENTS_OUTPUT = static_cast<long long>(P) * Q * K;

    float *input      = new float[TOTAL_UNIQUE_ELEMENTS_INPUT];
    float *weight     = new float[TOTAL_ELEMENTS_WEIGHT];
    float *output_ref = new float[TOTAL_UNIQUE_ELEMENTS_OUTPUT];

    bf16 *input_bf  = new bf16[TOTAL_ELEMENTS_INPUT];
    bf16 *weight_bf = new bf16[TOTAL_ELEMENTS_WEIGHT];
    bf16 *output_bf = new bf16[TOTAL_ELEMENTS_OUTPUT];
    float *output   = new float[TOTAL_ELEMENTS_OUTPUT];

    std::ifstream infile(argv[1]);

    std::cout << "Starting to enter!" << std::endl;

    for(int i = 0; i < TOTAL_UNIQUE_ELEMENTS_INPUT; i++) {
        infile >> input[i];
        if (infile.fail()) {
            std::cerr << "Error reading input at index " << i << std::endl;
            return 1;
        }
    }
    std::cout << "Finished loading inp" << std::endl;
    
    for(int i = 0; i < TOTAL_ELEMENTS_WEIGHT; i++) {
        infile >> weight[i];
        if (infile.fail()) {
            std::cerr << "Error reading weight at index " << i << std::endl;
            return 1;
        }
    }
    std::cout << "Finished loading wei" << std::endl;
    
    for(int i = 0; i < TOTAL_UNIQUE_ELEMENTS_OUTPUT; i++) {
        infile >> output_ref[i];
        if (infile.fail()) {
            std::cerr << "Error reading output_ref at index " << i << std::endl;
            return 1;
        }
    }
    std::cout << "Finished loading out" << std::endl;

    std::cout << "Finished loading file from " << argv[1] << "!" << std::endl;

    // replicate input
    for (int n = 0; n < TOTAL_ELEMENTS_INPUT; n++) {
        input_bf[n] = __float2bfloat16(input[n % TOTAL_UNIQUE_ELEMENTS_INPUT]);
    }
    for (int n = 0; n < TOTAL_ELEMENTS_WEIGHT; n++) {
        weight_bf[n] = __float2bfloat16(weight[n]);
    }
    for (int n = 0; n < TOTAL_ELEMENTS_OUTPUT; n++) {
        output_bf[n] = __float2bfloat16(0);
    }
    
    bf16 *d_input, *d_weight, *d_output; 
    cudaMalloc(&d_input,  TOTAL_ELEMENTS_INPUT * sizeof(bf16));
    cudaMalloc(&d_weight, TOTAL_ELEMENTS_WEIGHT * sizeof(bf16));
    cudaMalloc(&d_output, TOTAL_ELEMENTS_OUTPUT * sizeof(bf16));

    cudaMemcpy(d_input,  input_bf,  TOTAL_ELEMENTS_INPUT  * sizeof(bf16), cudaMemcpyHostToDevice);
    cudaMemcpy(d_weight, weight_bf, TOTAL_ELEMENTS_WEIGHT * sizeof(bf16), cudaMemcpyHostToDevice);
    cudaMemcpy(d_output, output_bf, TOTAL_ELEMENTS_OUTPUT * sizeof(bf16), cudaMemcpyHostToDevice);

    int gemm_m = N * P * Q;
    int gemm_n = K;
    int gemm_k = C * R * S;

    CUtensorMap* tma_a = tma::allocate_and_create_tensor_map<a_smem_tile>(d_input,  (gemm_m)/(64), (gemm_k)/(MMA_K));
    CUtensorMap* tma_b = tma::allocate_and_create_tensor_map<b_smem_tile>(d_weight, (gemm_n)/MMA_N, (gemm_k)/(MMA_K));
    CUtensorMap* tma_c = tma::allocate_and_create_tensor_map<c_smem_tile>(d_output, (gemm_m)/(64), (gemm_n)/(MMA_N));

    unsigned long mem_size = kittens::MAX_SHARED_MEMORY; 

    cudaFuncSetAttribute(
        simple_gemm, 
        cudaFuncAttributeMaxDynamicSharedMemorySize,
        mem_size
    ); 

    const dim3 grid_dim{(unsigned int)(gemm_n) / MMA_N, (unsigned int)(gemm_m) / MMA_M}; 
    std::cout << grid_dim.x << ' ' << grid_dim.y << std::endl;

    std::cout << "Starting computation" << std::endl;

    constexpr int ITERS = 1;
    auto start = std::chrono::high_resolution_clock::now();
    for(int i = 0; i < ITERS; i++) {
        simple_gemm<<<grid_dim, NUM_WARPGROUPS * kittens::WARPGROUP_THREADS, mem_size>>>(gemm_m, gemm_n, gemm_k, tma_a, tma_b, tma_c);
    }
    cudaDeviceSynchronize();
    auto end = std::chrono::high_resolution_clock::now();

    std::chrono::duration<double, std::micro> elapsed = end - start;
    
    std::cout << "Computation wall clock time: " << elapsed.count() / ITERS << " us" << std::endl;
    
    std::cout << "Realized FLOPs: " << (double(gemm_m) * gemm_n * gemm_k * 2 * ITERS) / elapsed.count() / 1e6 << " TFLOPs" << std::endl;
    CudaCheckError();
    cudaMemcpy(output_bf, d_output, TOTAL_ELEMENTS_OUTPUT * sizeof(bf16), cudaMemcpyDeviceToHost);

    for (int i = 0; i < TOTAL_ELEMENTS_OUTPUT; i++) {
        output[i] = __bfloat162float(output_bf[i]);
        // printf("%f\n", output[i]);
    }

    bool good = true; 
    float total_diff = 0; 

    float avg_output     = 0;
    float avg_output_ref = 0;

    std::ofstream o_ref_file("printouts/o_ref.txt");
    std::ofstream o_file("printouts/o.txt");
    std::ofstream diff_file("printouts/diff.txt");

    for (int i = 0; i < TOTAL_ELEMENTS_OUTPUT; i++) {
        float diff = abs(output[i] - output_ref[i % TOTAL_UNIQUE_ELEMENTS_OUTPUT]);
        total_diff += diff;

        avg_output     += output[i];
        avg_output_ref += output_ref[i % TOTAL_UNIQUE_ELEMENTS_OUTPUT];

        if (i < TOTAL_UNIQUE_ELEMENTS_OUTPUT) {
            o_ref_file << output_ref[i] << ' ';
            o_file << output[i] << ' ';
            diff_file << diff << ' ';
        }

        if (diff > 1e-3) {
            good = false;
        }
    }

    avg_output     /= TOTAL_ELEMENTS_OUTPUT;
    avg_output_ref /= TOTAL_ELEMENTS_OUTPUT;
    total_diff     /= TOTAL_ELEMENTS_OUTPUT;

    std::cout << "Average output: " << avg_output << std::endl;
    std::cout << "Average output ref: " << avg_output_ref << std::endl;
    std::cout << "Average diff: " << total_diff << std::endl;

    free(input);
    free(weight);
    free(output_ref);

    free(input_bf);
    free(weight_bf);
    free(output_bf);

    cudaFree(d_input);
    cudaFree(d_weight);
    cudaFree(d_output);

    return 0;
}